{
    "version": "https://jsonfeed.org/version/1",
    "title": "hexo-blog • All posts by \"大数据\" tag",
    "description": "record some markdown",
    "home_page_url": "https://ceilzcx.github.io/hexo-blog",
    "items": [
        {
            "id": "https://ceilzcx.github.io/hexo-blog/2021/10/29/big-data/big-data/",
            "url": "https://ceilzcx.github.io/hexo-blog/2021/10/29/big-data/big-data/",
            "title": "big-data",
            "date_published": "2021-10-29T14:23:31.000Z",
            "content_html": "<h2 id=\"大数据知识\"><a class=\"markdownIt-Anchor\" href=\"#大数据知识\">#</a> 大数据知识</h2>\n<h3 id=\"olap-和-oltp-的概念和比较\"><a class=\"markdownIt-Anchor\" href=\"#olap-和-oltp-的概念和比较\">#</a> OLAP 和 OLTP 的概念和比较</h3>\n<ul>\n<li>OLAP：联机分析处理。数据仓库的主要应用，支持复杂的数据操作。</li>\n<li>OLTP：连接事务处理。传统的关系型数据库的主要应用，主要是基本的事务处理。强调数据的实时性和内存效率，以及并发的操作</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>OLTP</th>\n<th>OLAP</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>数据</td>\n<td>最新的数据</td>\n<td>历史数据；聚合、多维集成的数据</td>\n</tr>\n<tr>\n<td>工作单位</td>\n<td>事务</td>\n<td>查询</td>\n</tr>\n<tr>\n<td>时间</td>\n<td>实时性</td>\n<td>存在一定延迟</td>\n</tr>\n<tr>\n<td>应用</td>\n<td>数据库</td>\n<td>数据仓库</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"hadoop-hdfs-hive-hbase的关系\"><a class=\"markdownIt-Anchor\" href=\"#hadoop-hdfs-hive-hbase的关系\">#</a>  <code>Hadoop</code> 、 <code>HDFS</code> 、 <code>Hive</code> 、 <code>HBase</code>  的关系</h3>\n<ul>\n<li>\n<p><code>Hadoop</code> ：分布式计算的开源框架</p>\n</li>\n<li>\n<p><code>HDFS</code> ：分布式文件系统（ <code>Hadoop</code>  三大组件之一）</p>\n</li>\n<li>\n<p><code>Hive</code> ：存储处理数据的  <code>sql</code> ， <code>Hive</code>  会将  <code>sql</code>  转化为  <code>MapReduce</code>  程序。</p>\n<p>本身并不存储数据，完全依赖于  <code>HDFS</code>   和  <code>MapReduce</code> 。</p>\n</li>\n<li>\n<p><code>HBase</code> ：基于  <code>HDFS</code>  的数据库， <code>NoSQL</code>  数据库，用于海量数据数据（亿）的随机查询</p>\n<p>物理表，提供一个超大的内存  <code>Hash</code>  表，通过他存储索引，方便查询操作</p>\n</li>\n<li>\n<p><code>Sqoop</code> ：为  <code>HBase</code>  提供了方便的  <code>RDBMS</code>  数据导入功能，使得传统的数据向  <code>HBase</code>  迁移变得非常方便</p>\n</li>\n</ul>\n<p><img data-src=\"\" alt=\"hadoop.png\"></p>\n",
            "tags": [
                "大数据"
            ]
        },
        {
            "id": "https://ceilzcx.github.io/hexo-blog/2021/10/28/big-data/hadoop/",
            "url": "https://ceilzcx.github.io/hexo-blog/2021/10/28/big-data/hadoop/",
            "title": "hadoop",
            "date_published": "2021-10-28T10:01:18.000Z",
            "content_html": "<h2 id=\"hadoop\"><a class=\"markdownIt-Anchor\" href=\"#hadoop\">#</a> Hadoop</h2>\n<blockquote>\n<p>Apache 下密集型数据分布式系统基础架构。</p>\n<p>实现海量数据的存储和分析计算</p>\n</blockquote>\n<p><strong>特点</strong></p>\n<ul>\n<li>高可靠性：多副本存储</li>\n<li>高拓展性：可以方便的动态拓展节点</li>\n<li>高效性：并行计算，汇总 —— MapReduce</li>\n<li>高容错性：自动分配失败的任务（一个节点的计算任务挂掉，会将该节点的计算子任务分配到另一个有该任务资源的节点上进行计算）</li>\n</ul>\n<h3 id=\"一-hdfs\"><a class=\"markdownIt-Anchor\" href=\"#一-hdfs\">#</a> 一、HDFS</h3>\n<blockquote>\n<p>分布式文件系统</p>\n</blockquote>\n<h4 id=\"namenode\"><a class=\"markdownIt-Anchor\" href=\"#namenode\">#</a> NameNode</h4>\n<blockquote>\n<p>存储文件的元数据（存储文件的信息，不存储数据）</p>\n</blockquote>\n<h4 id=\"datanode\"><a class=\"markdownIt-Anchor\" href=\"#datanode\">#</a> DataNode</h4>\n<blockquote>\n<p>存储文件块数据，以及数据的校验和</p>\n</blockquote>\n<h4 id=\"secondary-namenode-2nn\"><a class=\"markdownIt-Anchor\" href=\"#secondary-namenode-2nn\">#</a> Secondary NameNode (2NN)</h4>\n<blockquote>\n<p>NameNode 的数据备份（防止 NameNode 挂掉后，数据无法找到）</p>\n</blockquote>\n<h3 id=\"二-yarn\"><a class=\"markdownIt-Anchor\" href=\"#二-yarn\">#</a> 二、YARN</h3>\n<blockquote>\n<p>资源调度器</p>\n</blockquote>\n<h4 id=\"resourcemanager\"><a class=\"markdownIt-Anchor\" href=\"#resourcemanager\">#</a> ResourceManager</h4>\n<blockquote>\n<p>管理整个集群的资源（内存、CPU、磁盘、网络等）</p>\n</blockquote>\n<h4 id=\"nodemanager\"><a class=\"markdownIt-Anchor\" href=\"#nodemanager\">#</a> NodeManager</h4>\n<blockquote>\n<p>管理单个节点服务器资源</p>\n</blockquote>\n<h4 id=\"application-master\"><a class=\"markdownIt-Anchor\" href=\"#application-master\">#</a> Application Master</h4>\n<blockquote>\n<p>管理任务运行（任务在节点上运行）</p>\n</blockquote>\n<h4 id=\"container\"><a class=\"markdownIt-Anchor\" href=\"#container\">#</a> Container</h4>\n<blockquote>\n<p>容器（相当于任务运行的服务器），封装任务运行所需要的任务</p>\n</blockquote>\n",
            "tags": [
                "大数据"
            ]
        },
        {
            "id": "https://ceilzcx.github.io/hexo-blog/2021/10/09/big-data/Flink/",
            "url": "https://ceilzcx.github.io/hexo-blog/2021/10/09/big-data/Flink/",
            "title": "Flink",
            "date_published": "2021-10-09T15:10:11.000Z",
            "content_html": "<h2 id=\"what-is-flink\"><a class=\"markdownIt-Anchor\" href=\"#what-is-flink\">#</a> what is Flink？</h2>\n<blockquote>\n<p><strong>分布式</strong> 处理引擎</p>\n</blockquote>\n<h3 id=\"流\"><a class=\"markdownIt-Anchor\" href=\"#流\">#</a> 流</h3>\n<blockquote>\n<p>无边界 / 有边界 的 <strong>有状态</strong> 的计算</p>\n</blockquote>\n<ul>\n<li><strong>无边界</strong>：只定义开始，没有结束，数据摄入后立即执行（输入无限）</li>\n<li><strong>有边界</strong>：定义开始和结束。可以数据摄入后立即立即执行（<strong>实时</strong>），也可以等待全部输入（存储在存储引擎中）后批量执行（<strong>历史记录</strong>）</li>\n</ul>\n<p>任务 —— 并行处理</p>\n<h3 id=\"状态\"><a class=\"markdownIt-Anchor\" href=\"#状态\">#</a> 状态</h3>\n<blockquote>\n<p>只有在每一个单独的事件上进行转换操作的应用才不需要状态</p>\n</blockquote>\n<ul>\n<li><strong>多种状态基础类型</strong>：数据类型（value、map、list 等）</li>\n<li><strong> <code>State Backend</code> </strong>：管理状态。内存 /  <code>RocksDB</code></li>\n<li><strong>精确一次语义</strong>：处理故障，保证状态一致性</li>\n<li><strong>超大数据量状态</strong>：利用其异步以及增量式的 checkpoint 算法，存储数 TB 级别的应用状态。</li>\n<li><strong>可弹性伸缩的应用</strong>：在更多或更少的工作节点上对状态进行重新分布，支持有状态应用的分布式的横向伸缩。</li>\n</ul>\n<h3 id=\"时间\"><a class=\"markdownIt-Anchor\" href=\"#时间\">#</a> 时间</h3>\n<blockquote>\n<p>事件总是在特定时间点发生，所以大多数的事件流都拥有事件本身所固有的时间语义</p>\n</blockquote>\n<ul>\n<li>\n<p><strong>事件时间模式</strong>：本身自带的时间戳进行结果的计算。保证准确性和一致性</p>\n<p>为什么自带时间戳？例如窗口模式，将同一个范围的时间戳放在一个 bucket 里面</p>\n</li>\n<li>\n<p><strong>Watermark 支持</strong>：衡量事件时间进展。平衡处理延时和完整性的灵活机制（Future）</p>\n<p>什么是 watermark？简单的举例：时间戳为 1-10 的数据按顺序进入 task Manager 执行，如果按照 5 的范围设置，那么等到 5 的时间戳到达说明 1-5 的数据都已经拿到，关闭对应的 bucket，执行任务；但是数据存在乱序的可能，可能 5 的数据已经拿到，但是 3 的数据在后面，如果关闭了 bucket 那么 3 的数据就丢失，因此可以通过设置 watermark，如果设置 watermark 为 2，拿到 5 的数据时，判断 5-2=3，不关闭 bucket，等到拿到 7 的数据关闭 1-5 的 bucket。因此设置合理的 watermark 可以解决大部分低延迟的数据。</p>\n</li>\n<li>\n<p><strong>迟到数据处理</strong>：当以带有 watermark 的事件时间模式处理数据流时，在计算完成之后仍会有相关数据到达。这样的事件被称为迟到事件。Flink 提供了多种处理迟到数据的选项，例如将这些数据重定向到旁路输出（side output）或者更新之前完成计算的结果。</p>\n</li>\n<li>\n<p><strong>处理时间模式</strong>：处理时间语义。处理时间模式根据处理引擎的机器时钟触发计算，一般适用于有着严格的低延迟需求，并且能够容忍近似结果的流处理应用。</p>\n</li>\n</ul>\n<h3 id=\"分层-api\"><a class=\"markdownIt-Anchor\" href=\"#分层-api\">#</a> 分层 API</h3>\n<ul>\n<li>High-level Analytics API：只需要写 SQL / Table API</li>\n<li>DataStream API：写数据流和批处理，可以调用 streams 和 windows</li>\n<li>ProcessFunction：Stateful Event-Driven Applications，可以调用 events、state 和 time</li>\n</ul>\n<h3 id=\"运行架构\"><a class=\"markdownIt-Anchor\" href=\"#运行架构\">#</a> 运行架构</h3>\n<h4 id=\"作业管理器jobmanager\"><a class=\"markdownIt-Anchor\" href=\"#作业管理器jobmanager\">#</a> 作业管理器（JobManager）</h4>\n<h3 id=\"流处理\"><a class=\"markdownIt-Anchor\" href=\"#流处理\">#</a> 流处理</h3>\n<h4 id=\"特点\"><a class=\"markdownIt-Anchor\" href=\"#特点\">#</a> 特点</h4>\n<ul>\n<li>event：事件触发，具有极强的时间性（事件发生、事件进入、事件处理时间 等）</li>\n<li>Stream：事件流，无界</li>\n<li>Process：流处理，</li>\n</ul>\n<h3 id=\"双流join操作\"><a class=\"markdownIt-Anchor\" href=\"#双流join操作\">#</a> 双流 Join 操作</h3>\n<ul>\n<li>join()</li>\n<li>coGroup()</li>\n<li>intervalJoin()</li>\n</ul>\n<h4 id=\"1-join\"><a class=\"markdownIt-Anchor\" href=\"#1-join\">#</a> 1、join()</h4>\n<blockquote>\n<p>对应 mysql 的 inner join</p>\n</blockquote>\n<p>通过一个窗口，进行 join 操作，简单易用。</p>\n<p>存在问题：一个流的数据存在延迟时，另一个流的数据没有对应的 join 数据。</p>\n<h4 id=\"2-cogroup\"><a class=\"markdownIt-Anchor\" href=\"#2-cogroup\">#</a> 2、coGroup()</h4>\n<blockquote>\n<p>对应 mysql 的 left/right outer join</p>\n</blockquote>\n<p>双重循环</p>\n<h4 id=\"3-intervaljoin\"><a class=\"markdownIt-Anchor\" href=\"#3-intervaljoin\">#</a> 3、intervalJoin()</h4>\n<p>按照指定字段以及右流相对左流偏移的时间区间进行关联，即：</p>\n<blockquote>\n<p>right.timestamp ∈ [left.timestamp + lowerBound; left.timestamp + upperBound]</p>\n</blockquote>\n<h2 id=\"架构和源码\"><a class=\"markdownIt-Anchor\" href=\"#架构和源码\">#</a> 架构和源码</h2>\n<h3 id=\"flink-connector-jdbc\"><a class=\"markdownIt-Anchor\" href=\"#flink-connector-jdbc\">#</a> flink-connector-jdbc</h3>\n<h4 id=\"upsert\"><a class=\"markdownIt-Anchor\" href=\"#upsert\">#</a> upsert</h4>\n<p>作为 sink 向外部数据库写入数据时，如果使用 DDL 定义的主键，连接器将在 upsert 模式下操作（需要保证幂等性），否则使用 append 操作（这时插入主键相同的数据会出现主键冲突的异常）。</p>\n<h4 id=\"cache\"><a class=\"markdownIt-Anchor\" href=\"#cache\">#</a> cache</h4>\n<p>JDBC 可以在临时连接中用作查找源。</p>\n<p>默认情况下，不确定缓存查找。可以设置  <code>lookup.cache.max-rows</code>  和  <code>lookup.cache.ttl</code>  设置启动它.</p>\n<p>使用缓存存在数据不是最新的问题，因此需要合理设置最大行和过期时间。</p>\n<h4 id=\"catalog\"><a class=\"markdownIt-Anchor\" href=\"#catalog\">#</a>  <code>catalog</code></h4>\n<blockquote>\n<p>目录</p>\n</blockquote>\n<p>将 database → table 的形式转出类似目录的形式</p>\n<h4 id=\"dialect\"><a class=\"markdownIt-Anchor\" href=\"#dialect\">#</a>  <code>dialect</code></h4>\n<blockquote>\n<p>方言，不同 JDBC 语法的差异</p>\n</blockquote>\n<p>upsert 操作参考： <code>JdbcDialect.getUpsertStatement</code></p>\n<h4 id=\"table\"><a class=\"markdownIt-Anchor\" href=\"#table\">#</a> table</h4>\n<p>Source、Sink、Function</p>\n<p>TableSchema 在 table-common 包中</p>\n<h4 id=\"packageversion113\"><a class=\"markdownIt-Anchor\" href=\"#packageversion113\">#</a> package(version：1.13)</h4>\n<p>maven 包可能不存在，在  <code>settings.xml</code>  添加国际镜像</p>\n<figure class=\"highlight tex\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;mirror&gt;</span><br><span class=\"line\">\t&lt;id&gt;mapr-public&lt;/id&gt;</span><br><span class=\"line\">\t&lt;mirrorOf&gt;mapr-releases&lt;/mirrorOf&gt;</span><br><span class=\"line\">\t&lt;name&gt;mapr-releases&lt;/name&gt;</span><br><span class=\"line\">\t&lt;url&gt;https://maven.aliyun.com/repository/mapr-public&lt;/url&gt;</span><br><span class=\"line\">&lt;/mirror&gt;</span><br></pre></td></tr></table></figure>\n<p>打包执行  <code>mvn clean install -DskipTests -Dfast -T 4 -Drat.skip=true </code>  ，最后一句一定要加，用来跳过 license，不然会报下面错误</p>\n<figure class=\"highlight tex\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Failed to execute goal org.apache.rat:apache-rat-plugin:0.12:check (default) on project flink-parent: Too many files with unapproved license: 4 See RAT report in: D:<span class=\"keyword\">\\ffffff</span><span class=\"keyword\">\\flink</span>-release-1.10.0<span class=\"keyword\">\\flink</span>-release-1.10.0<span class=\"keyword\">\\target</span><span class=\"keyword\">\\rat</span>.txt</span><br></pre></td></tr></table></figure>\n<p>flink-runtime-web 下载 node 速度较慢，下载超时失败。修改 pom.xml 的配置信息，如果已经操作，需要删除 web-dashboard 的 node modules</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 修改</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">arguments</span>&gt;</span>ci --cache-max=0 --no-save<span class=\"tag\">&lt;/<span class=\"name\">arguments</span>&gt;</span></span><br><span class=\"line\">// 替换</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">arguments</span>&gt;</span>install -registry=https://registry.npm.taobao.org --cache-max=0 --no-save<span class=\"tag\">&lt;/<span class=\"name\">arguments</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>代码规范</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn spotless:apply</span><br></pre></td></tr></table></figure>\n<p>node 添加 其他下载源</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">nodeDownloadRoot</span>&gt;</span>https://registry.npm.taobao.org/dist/<span class=\"tag\">&lt;/<span class=\"name\">nodeDownloadRoot</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">npmDownloadRoot</span>&gt;</span>https://registry.npmjs.org/npm/-/<span class=\"tag\">&lt;/<span class=\"name\">npmDownloadRoot</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">nodeVersion</span>&gt;</span>v10.9.0<span class=\"tag\">&lt;/<span class=\"name\">nodeVersion</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>局部打包，例如我要打包 flink-connector 模块， <code>-pl</code> ：指定需要打包的模块， <code>-am</code> ：加载依赖模块</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn clean install -pl flink-connectors -am -Drat.skip=true</span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "大数据"
            ]
        }
    ]
}